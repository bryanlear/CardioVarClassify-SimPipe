
### Mathematical frameworks for transforming outrageously quantities of genomic data - largely generated by next-generation sequencing (NGS) technologies - into meaningful insightsn ###

how to mathematically formulate ''common'' and ''rare'' into a problem? how to visualize genomic data  analogously to a 3D physicsl structure? what mathematical frameworks are there available? 
Available deep learning architectures
Transformer architectures 

* The following papers focus on ''novel algorithms'', ''statistical models'', ''mathematical formalisms'' to shape landscape of genomic analysis and interpretation. 


######################

ARCHITECTURES IN GENOMICS

######################


- Attention is all you need. Vaswani A, Shazeer N, Parmar N, et al. 2017 (introduction of transformer architecture)

- Epigenome-based splicing prediction using a recurrent neural network. Lee D, Zhang J, Liu J, Gerstein M. 2020. (mathematical formulation of RNN architecture for predicting exon inclusion from genomic and epigenomic sequences)

- Effective gene expression prediction from sequence by integrating long-range interactions (Enformer). Avsec Å½, Agarwal V, Visentin D, et al.	Nature Methods. 2021 ( introduction ENformer, transformer-based for predicting gene expression from DNA sequences effectively capturing longm-range regulatory interactions)

- Long short-term memory. Hochreiter S, Schmidhuber J. 1997

######################

Pr() / BAYESIAN FOR VARIANT ANALYSIS 

######################

(to model uncertainty, integrate prior evidence)
How to account for sample heterogeneity? e.g., between individuals differences, tissue types, cancer types


- A probabilistic modeling framework for genomic networks incorporating sample heterogeneity (GraphR). Chen S, Zhao S, Wang G, et al. 2024

- A probabilistic graphical model for estimating selection coefficient of nonsynonymous variants from human population sequence data. Zhao et al 2025. PREPRINT NOT PEER REVIEWED YET. 

######################

LLMs

######################

- A universal SNP and small-indel variant caller using deep neural networks. Poplin R, Chang PC, Alexander D, et al. 2018

- DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome. Ji Y, Zhou Z, Liu H, Davuluri RV. 2021

- DNABERT-2: Efficient Foundation Model and Benchmark for Multi-Species Genomes. same people

- The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics. Dalla-Torre H, Gligorijevic V, Life TTAC, Zitnik M.  2023


######################
######################
######################

other:

- ''Before the widespread adoption of deep learning, several foundational Variant Effect Prediction (VEP) algorithms were developed that established key principles for distinguishing potentially deleterious genetic variants from neutral ones. These tools often relied on evolutionary conservation, sequence homology, and structural information, employing sophisticated feature engineering and statistical or early machine learning models.''
    * SIFT
    * PolyPhen-2
    * CADD


- GWAS succes with common variants, limitations with rare or complex non-coding effects. 

- 
